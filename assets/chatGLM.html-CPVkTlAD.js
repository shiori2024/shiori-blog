import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,o as c,c as s,a as l,b as t,d as e,e as a,f as p}from"./app-BELSUGU6.js";const d={},h=t("p",null,"ChatGLM 是清华大学的开源项目，其 ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型， ，具有 62 亿参数。虽说参数在GPT中不算高，但是作为消费级的显卡上进行本地部署就非常实用。",-1),m=t("h1",{id:"官网",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#官网"},[t("span",null,"官网")])],-1),g={href:"https://chatglm.cn/blog",target:"_blank",rel:"noopener noreferrer"},u={href:"https://github.com/THUDM/ChatGLM-6B",target:"_blank",rel:"noopener noreferrer"},_=t("h1",{id:"教学视频",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#教学视频"},[t("span",null,"教学视频")])],-1),f=p(`<p>根据视频简介提供的链接，将 模型<code>model</code>，主程序 <code>ChatGLM-webui</code>，环境包以及更新包下载下来。</p><h1 id="使用过程" tabindex="-1"><a class="header-anchor" href="#使用过程"><span>使用过程</span></a></h1><p>目录结构如下： <img src="" alt="img1" loading="lazy"></p><p>对应你的显存大小来启用bat</p><h2 id="本地部署效果图" tabindex="-1"><a class="header-anchor" href="#本地部署效果图"><span>本地部署效果图</span></a></h2><figure><img src="https://s1.ax1x.com/2023/04/04/pp4dZIU.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h2 id="个人使用" tabindex="-1"><a class="header-anchor" href="#个人使用"><span>个人使用</span></a></h2><h3 id="常见问题" tabindex="-1"><a class="header-anchor" href="#常见问题"><span>常见问题</span></a></h3><p>报错：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>Symbol cudaLaunchKernel not found in C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common\\cudart64_65.dll

RuntimeError: Library cublasLt is not initialized
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,10),G={href:"https://developer.nvidia.com/cuda-downloads",target:"_blank",rel:"noopener noreferrer"};function y(C,L){const n=o("ExternalLinkIcon"),r=o("BiliBili");return c(),s("div",null,[h,l(" more "),m,t("p",null,[t("a",g,[e("博客"),a(n)]),e(" | "),t("a",u,[e("ChatGLM-6B"),a(n)])]),_,a(r,{bvid:"BV1E24y1u7Go","low-quality":""}),f,t("p",null,[e("去"),t("a",G,[e("NVIDIA官网"),a(n)]),e("安装cuda即可，安装时默认安装路径，直接下一步即可。")])])}const M=i(d,[["render",y],["__file","chatGLM.html.vue"]]),v=JSON.parse('{"path":"/posts/chatGLM.html","title":"ChatGLM","lang":"zh-CN","frontmatter":{"icon":"edit","title":"ChatGLM","date":"2021-07-21T14:24:43.000Z","category":["AIGC"],"tag":["分享","开源","AI","ChatGPT"],"star":true,"sticky":true,"description":"ChatGLM 是清华大学的开源项目，其 ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型， ，具有 62 亿参数。虽说参数在GPT中不算高，但是作为消费级的显卡上进行本地部署就非常实用。 官网 博客 | ChatGLM-6B 教学视频 ","head":[["meta",{"property":"og:url","content":"https://shiori.fun/posts/chatGLM.html"}],["meta",{"property":"og:site_name","content":"花诽语"}],["meta",{"property":"og:title","content":"ChatGLM"}],["meta",{"property":"og:description","content":"ChatGLM 是清华大学的开源项目，其 ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型， ，具有 62 亿参数。虽说参数在GPT中不算高，但是作为消费级的显卡上进行本地部署就非常实用。 官网 博客 | ChatGLM-6B 教学视频 "}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://s1.ax1x.com/2023/04/04/pp4dZIU.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-18T15:02:23.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"ChatGLM"}],["meta",{"property":"article:author","content":"shiori"}],["meta",{"property":"article:tag","content":"分享"}],["meta",{"property":"article:tag","content":"开源"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:tag","content":"ChatGPT"}],["meta",{"property":"article:published_time","content":"2021-07-21T14:24:43.000Z"}],["meta",{"property":"article:modified_time","content":"2024-02-18T15:02:23.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ChatGLM\\",\\"image\\":[\\"https://s1.ax1x.com/2023/04/04/pp4dZIU.png\\"],\\"datePublished\\":\\"2021-07-21T14:24:43.000Z\\",\\"dateModified\\":\\"2024-02-18T15:02:23.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"shiori\\",\\"url\\":\\"https://shiori.fun\\",\\"email\\":\\"shiori2024@163.com\\"}]}"]]},"headers":[{"level":2,"title":"本地部署效果图","slug":"本地部署效果图","link":"#本地部署效果图","children":[]},{"level":2,"title":"个人使用","slug":"个人使用","link":"#个人使用","children":[{"level":3,"title":"常见问题","slug":"常见问题","link":"#常见问题","children":[]}]}],"git":{"createdTime":1708268543000,"updatedTime":1708268543000,"contributors":[{"name":"shiori2024","email":"shiori2024@163.com","commits":1}]},"readingTime":{"minutes":0.83,"words":248},"filePathRelative":"posts/chatGLM.md","localizedDate":"2021年7月21日","excerpt":"<p>ChatGLM 是清华大学的开源项目，其 ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，\\n，具有 62 亿参数。虽说参数在GPT中不算高，但是作为消费级的显卡上进行本地部署就非常实用。</p>\\n","autoDesc":true}');export{M as comp,v as data};
